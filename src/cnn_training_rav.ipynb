{"cells":[{"cell_type":"markdown","metadata":{"id":"g2DwsQiSb6xR"},"source":["## Oxford AI Summit: Kaggle dataset training notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4Vqn5oayGjh","outputId":"9c896135-66d4-4271-b217-946ac7713ca2"},"outputs":[],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pk4SACVlb6xT"},"outputs":[],"source":["import os\n","\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.model_selection import train_test_split\n","\n","from kaggle.api.kaggle_api_extended import KaggleApi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzngwmYNx6NO"},"outputs":[],"source":["# Ensure GPU is available\n","if tf.config.list_physical_devices('GPU'):\n","    print(\"GPU is available\")\n","else:\n","    print(\"GPU is not available\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8ye6k36lXxA"},"outputs":[],"source":["api = KaggleApi()\n","# api.authenticate()\n","\n","dataset = 'paramaggarwal/fashion-product-images-dataset'\n","destination_folder = 'fashion_product_images'\n","\n","api.dataset_download_files(dataset, path=destination_folder, unzip=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOWlg4NIqX6o"},"outputs":[],"source":["# Load the metadata\n","metadata_path = 'fashion_product_images/fashion-dataset/styles.csv'\n","metadata = pd.read_csv(metadata_path, on_bad_lines='skip')\n","\n","# Display the first few rows of the metadata\n","print(metadata.head())\n","print(metadata.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4j8ztQcqkYH"},"outputs":[],"source":["# Replace 'id' with the correct column name containing the unique identifier\n","image_folder = 'fashion_product_images/fashion-dataset/images'\n","metadata['image_path'] = metadata.apply(lambda row: os.path.join(image_folder, str(row['id']) + '.jpg'), axis=1)\n","metadata = metadata[metadata['image_path'].apply(os.path.exists)]\n","\n","# Select relevant columns and encode labels\n","metadata = metadata[['image_path', 'articleType']]\n","metadata['articleType'] = metadata['articleType'].astype('category')\n","metadata['label'] = metadata['articleType'].cat.codes\n","\n","# Ensure each class has at least 2 samples\n","min_samples_per_class = 2\n","class_counts = metadata['label'].value_counts()\n","valid_classes = class_counts[class_counts >= min_samples_per_class].index\n","metadata = metadata[metadata['label'].isin(valid_classes)]\n","\n","# Split into training and validation sets\n","train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['label'], random_state=42)\n","\n","# Convert the labels to strings\n","train_df['label'] = train_df['label'].astype(str)\n","val_df['label'] = val_df['label'].astype(str)\n","\n","print(f'Training set size: {len(train_df)}')\n","print(f'Validation set size: {len(val_df)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9wdwGfSsclI"},"outputs":[],"source":["# Image data generator with augmentation for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# Image data generator for validation (without augmentation)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Data generators\n","train_generator = train_datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='image_path',\n","    y_col='label',\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","val_generator = val_datagen.flow_from_dataframe(\n","    val_df,\n","    x_col='image_path',\n","    y_col='label',\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKaZJBXMb6xV"},"outputs":[],"source":["# Build the CNN model\n","num_classes = metadata['label'].nunique()\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(num_classes, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjsuL6dRvJro"},"outputs":[],"source":["# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gw-fLn0Mb6xV"},"outputs":[],"source":["# Train the model\n","checkpoint = ModelCheckpoint('fashion_mnist_model.keras', save_best_only=True)\n","history = model.fit(\n","    train_generator,\n","    epochs=1,\n","    validation_data=val_generator,\n","    callbacks=[checkpoint],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FVF0p62u_Ak"},"outputs":[],"source":["val_loss, val_acc = model.evaluate(val_generator)\n","print(f'Validation loss: {val_loss}')\n","print(f'Validation accuracy: {val_acc}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0PbKbMfb6xV"},"outputs":[],"source":["# Save the model\n","model.save('fashion_mnist_model_final.keras')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
