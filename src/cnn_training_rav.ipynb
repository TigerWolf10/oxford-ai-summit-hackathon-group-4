{"cells":[{"cell_type":"markdown","metadata":{"id":"g2DwsQiSb6xR"},"source":["## Oxford AI Summit: Kaggle dataset training notebook"]},{"cell_type":"code","source":["!pip install kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4Vqn5oayGjh","outputId":"9c896135-66d4-4271-b217-946ac7713ca2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pk4SACVlb6xT"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoImageProcessor, AutoModelForImageClassification\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","\n","import os\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import pandas as pd"]},{"cell_type":"code","source":["# Ensure GPU is available\n","if tf.config.list_physical_devices('GPU'):\n","    print(\"GPU is available\")\n","else:\n","    print(\"GPU is not available\")"],"metadata":{"id":"zzngwmYNx6NO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8ye6k36lXxA"},"outputs":[],"source":["api = KaggleApi()\n","# api.authenticate()\n","\n","dataset = 'paramaggarwal/fashion-product-images-dataset'\n","destination_folder = 'fashion_product_images'\n","\n","api.dataset_download_files(dataset, path=destination_folder, unzip=True)"]},{"cell_type":"code","source":["# Load the metadata\n","metadata_path = 'fashion_product_images/fashion-dataset/styles.csv'\n","metadata = pd.read_csv(metadata_path, on_bad_lines='skip')\n","\n","# Display the first few rows of the metadata\n","print(metadata.head())\n","print(metadata.columns)"],"metadata":{"id":"pOWlg4NIqX6o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace 'id' with the correct column name containing the unique identifier\n","image_folder = 'fashion_product_images/fashion-dataset/images'\n","metadata['image_path'] = metadata.apply(lambda row: os.path.join(image_folder, str(row['id']) + '.jpg'), axis=1)\n","metadata = metadata[metadata['image_path'].apply(os.path.exists)]\n","\n","# Select relevant columns and encode labels\n","metadata = metadata[['image_path', 'articleType']]\n","metadata['articleType'] = metadata['articleType'].astype('category')\n","metadata['label'] = metadata['articleType'].cat.codes\n","\n","# Ensure each class has at least 2 samples\n","min_samples_per_class = 2\n","class_counts = metadata['label'].value_counts()\n","valid_classes = class_counts[class_counts >= min_samples_per_class].index\n","metadata = metadata[metadata['label'].isin(valid_classes)]\n","\n","# Split into training and validation sets\n","train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['label'], random_state=42)\n","\n","# Convert the labels to strings\n","train_df['label'] = train_df['label'].astype(str)\n","val_df['label'] = val_df['label'].astype(str)\n","\n","print(f'Training set size: {len(train_df)}')\n","print(f'Validation set size: {len(val_df)}')"],"metadata":{"id":"Q4j8ztQcqkYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image data generator with augmentation for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# Image data generator for validation (without augmentation)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Data generators\n","train_generator = train_datagen.flow_from_dataframe(\n","    train_df,\n","    x_col='image_path',\n","    y_col='label',\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","val_generator = val_datagen.flow_from_dataframe(\n","    val_df,\n","    x_col='image_path',\n","    y_col='label',\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n"],"metadata":{"id":"V9wdwGfSsclI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKaZJBXMb6xV"},"outputs":[],"source":["# Build the CNN model\n","num_classes = metadata['label'].nunique()\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(num_classes, activation='softmax')\n","])"]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"metadata":{"id":"JjsuL6dRvJro"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gw-fLn0Mb6xV"},"outputs":[],"source":["# Train the model\n","checkpoint = ModelCheckpoint('fashion_mnist_model.keras', save_best_only=True)\n","history = model.fit(\n","    train_generator,\n","    epochs=1,\n","    validation_data=val_generator,\n","    callbacks=[checkpoint],\n",")"]},{"cell_type":"code","source":["val_loss, val_acc = model.evaluate(val_generator)\n","print(f'Validation loss: {val_loss}')\n","print(f'Validation accuracy: {val_acc}')"],"metadata":{"id":"9FVF0p62u_Ak"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0PbKbMfb6xV"},"outputs":[],"source":["\n","# Save the model\n","model.save('fashion_mnist_model_final.keras')\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}