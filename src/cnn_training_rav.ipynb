{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2DwsQiSb6xR"
      },
      "source": [
        "## Oxford AI Summit: Kaggle dataset training notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Vqn5oayGjh",
        "outputId": "684c8846-97ca-4517-dd2f-96eac3c7afcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (1.6.14)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: bleach in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (2.2.1)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from requests->kaggle) (3.7)\n",
            "Requirement already satisfied: webencodings in c:\\users\\konrad\\documents\\projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Konrad\\Documents\\Projects\\oxford-ai-summit-hackathon-group-4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pk4SACVlb6xT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzngwmYNx6NO",
        "outputId": "68447921-6110-4757-cf8c-7b1863d13ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on GPU or CPU\n"
          ]
        }
      ],
      "source": [
        "# Enable TPU if available\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print('Running on TPU')\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()  # Default strategy for CPU and GPU\n",
        "    print('Running on GPU or CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8ye6k36lXxA",
        "outputId": "e5e8206c-44e3-4a73-8ed5-9e146139a270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 28] No space left on device",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mparamaggarwal/fashion-product-images-dataset\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m destination_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfashion_product_images\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m api\u001b[39m.\u001b[39;49mdataset_download_files(dataset, path\u001b[39m=\u001b[39;49mdestination_folder, unzip\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[1;32mc:\\Users\\Konrad\\Documents\\Projects\\oxford-ai-summit-hackathon-group-4\\venv\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py:1509\u001b[0m, in \u001b[0;36mKaggleApi.dataset_download_files\u001b[1;34m(self, dataset, path, force, quiet, unzip, licenses)\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m     \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(outfile) \u001b[39mas\u001b[39;00m z:\n\u001b[1;32m-> 1509\u001b[0m         z\u001b[39m.\u001b[39;49mextractall(effective_path)\n\u001b[0;32m   1510\u001b[0m \u001b[39mexcept\u001b[39;00m zipfile\u001b[39m.\u001b[39mBadZipFile \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1511\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mBad zip file, please report on \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mwww.github.com/kaggle/kaggle-api\u001b[39m\u001b[39m'\u001b[39m, e)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1647\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1644\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(path)\n\u001b[0;32m   1646\u001b[0m \u001b[39mfor\u001b[39;00m zipinfo \u001b[39min\u001b[39;00m members:\n\u001b[1;32m-> 1647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_member(zipinfo, path, pwd)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1702\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1698\u001b[0m     \u001b[39mreturn\u001b[39;00m targetpath\n\u001b[0;32m   1700\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(member, pwd\u001b[39m=\u001b[39mpwd) \u001b[39mas\u001b[39;00m source, \\\n\u001b[0;32m   1701\u001b[0m      \u001b[39mopen\u001b[39m(targetpath, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m target:\n\u001b[1;32m-> 1702\u001b[0m     shutil\u001b[39m.\u001b[39;49mcopyfileobj(source, target)\n\u001b[0;32m   1704\u001b[0m \u001b[39mreturn\u001b[39;00m targetpath\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\shutil.py:205\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[0;32m    204\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m fdst_write(buf)\n",
            "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
          ]
        }
      ],
      "source": [
        "api = KaggleApi()\n",
        "\n",
        "dataset = 'paramaggarwal/fashion-product-images-dataset'\n",
        "destination_folder = 'fashion_product_images'\n",
        "\n",
        "api.dataset_download_files(dataset, path=destination_folder, unzip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4j8ztQcqkYH",
        "outputId": "bc4e8333-0783-4cd5-d548-4c39b98f421d"
      },
      "outputs": [],
      "source": [
        "# Load the metadata\n",
        "metadata_path = 'fashion_product_images/fashion-dataset/styles.csv'\n",
        "metadata = pd.read_csv(metadata_path, on_bad_lines='skip')\n",
        "\n",
        "# Display the first few rows of the metadata\n",
        "print(metadata.head())\n",
        "print(metadata.columns)\n",
        "\n",
        "# Replace 'id' with the correct column name containing the unique identifier\n",
        "image_folder = 'fashion_product_images/fashion-dataset/images'\n",
        "metadata['image_path'] = metadata.apply(lambda row: os.path.join(image_folder, str(row['id']) + '.jpg'), axis=1)\n",
        "metadata = metadata[metadata['image_path'].apply(os.path.exists)]\n",
        "\n",
        "# Select relevant columns and encode labels\n",
        "metadata = metadata[['image_path', 'articleType']]\n",
        "metadata['articleType'] = metadata['articleType'].astype('category')\n",
        "metadata['label'] = metadata['articleType'].cat.codes\n",
        "\n",
        "# Ensure each class has at least 2 samples\n",
        "min_samples_per_class = 2\n",
        "class_counts = metadata['label'].value_counts()\n",
        "valid_classes = class_counts[class_counts >= min_samples_per_class].index\n",
        "metadata = metadata[metadata['label'].isin(valid_classes)]\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['label'], random_state=5)\n",
        "\n",
        "# Convert the labels to strings\n",
        "train_df['label'] = train_df['label'].astype(str)\n",
        "val_df['label'] = val_df['label'].astype(str)\n",
        "\n",
        "# Find common classes\n",
        "train_classes = set(train_df['label'].unique())\n",
        "val_classes = set(val_df['label'].unique())\n",
        "print(f\"Len: train({len(train_classes)}), val({len(val_classes)})\")\n",
        "print(train_classes - val_classes)\n",
        "common_classes = train_classes.intersection(val_classes)\n",
        "\n",
        "# Filter dataframes to only include common classes\n",
        "train_df = train_df[train_df['label'].isin(common_classes)]\n",
        "val_df = val_df[val_df['label'].isin(common_classes)]\n",
        "\n",
        "# Print the number of unique labels\n",
        "num_classes = len(common_classes)\n",
        "print(f'Number of unique labels: {num_classes}')\n",
        "print(f'Training set size: {len(train_df)}')\n",
        "print(f'Validation set size: {len(val_df)}')\n",
        "\n",
        "print(f'Training set size: {len(train_df)}')\n",
        "print(f'Validation set size: {len(val_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9wdwGfSsclI",
        "outputId": "1d1f6ff2-9856-445e-b0a2-71ad72290c1a"
      },
      "outputs": [],
      "source": [
        "# Image data generator with augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Image data generator for validation (without augmentation)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='image_path',\n",
        "    y_col='label',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKaZJBXMb6xV",
        "outputId": "da10066c-d2b7-4fb7-f148-798e6501a35e"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model within the strategy scope\n",
        "with strategy.scope():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')  # Adjusted number of output units\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw-fLn0Mb6xV",
        "outputId": "2c034cf5-4db1-4f81-c7e3-c994b67aa7cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.EarlyStopping at 0x208d51268e0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callback = EarlyStopping(\n",
        "    monitor=\"categorical_crossentropy\",\n",
        "    min_delta=0,\n",
        "    patience=3,\n",
        "    verbose=0,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mfashion_mnist_model.keras\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m     train_generator,\n\u001b[0;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m      6\u001b[0m     validation_data\u001b[39m=\u001b[39mval_generator,\n\u001b[0;32m      7\u001b[0m     callbacks\u001b[39m=\u001b[39m[checkpoint],\n\u001b[0;32m      8\u001b[0m )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "checkpoint = ModelCheckpoint('fashion_mnist_model.keras', save_best_only=True)\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FVF0p62u_Ak"
      },
      "outputs": [],
      "source": [
        "# Basic evaluation\n",
        "val_loss, val_acc = model.evaluate(val_generator)\n",
        "print(f'Validation loss: {val_loss}')\n",
        "print(f'Validation accuracy: {val_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0PbKbMfb6xV"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('fashion_mnist_model_final.keras')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
